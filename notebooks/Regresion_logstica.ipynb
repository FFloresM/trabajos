{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 03: Regresión Logística\n",
    "\n",
    "El objetivo de esta actividad es que programes tú mismo el algoritmo de entrenamiento del modelo de Regresión Logística. Para probar tu modelo vas a tener que usar el _dataset_ de flores _Iris_.\n",
    "\n",
    "## Parte 1 (3 pts): programando el modelo\n",
    "\n",
    "En el codigo de abajo hay una clase llamada `LogisticRegression` cuyo constructor recibe como parámetro el número de _features_ que espera recibir. Tienes que completar esta clase para que pueda entrenar y predecir. Lo que necesitas es:\n",
    "\n",
    "- Programar el método `train`, que vendría a ser equivalente al método `fit` de Scikit Learn. Tienes que utilizar el algoritmo _Gradient Descent_ visto en clases.\n",
    "- Programar el método `predict` que asume que tu modelo ya está entrenado.\n",
    "\n",
    "Para hacer esto puedes hacer los supuestos razonables que estimes conveniente. Además, si te acomoda trabajar sin clases puedes hacerlo, mientras uses el algoritmo de _Gradient Descent_. **Importante**: puedes asumir que una instancia es \"positiva\" si la probabilidad es `>=` que 0.5.\n",
    "\n",
    "Recuerda además que el gradiente de la función objetivo para cada $\\beta_i$ es:\n",
    "\n",
    "$$\n",
    "\\frac{\\delta}{\\delta \\beta_i}L(\\beta) = \\frac{1}{n} \\sum_{i=1}^n (\\sigma(\\beta^T x_i) - y_i) x_i^j\n",
    "$$\n",
    "\n",
    "Donde $L(\\beta)$ es la función objetivo, $\\beta$ es el vector de coeficientes para la regresión, tenemos $n$ filas en nuestro _dataset_, $\\sigma(x)$ es la función $\\frac{1}{1 + e^{-x}}$, $x_i$ es la fila $i$ de nuestro dataset (y asociado tiene su respuesta $y_i$) y finalmente $x_i^j$ es la columna $j$ de la fila $i$ en nuestro _dataset_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.4141859  0.36435248 0.48650221]\n"
     ]
    }
   ],
   "source": [
    "# Tienes que programar la parte 1 aquí\n",
    "import numpy as np\n",
    "\n",
    "# La función sigmoide\n",
    "def sigmoid(x):    \n",
    "    output = 1 / (1 + np.exp(-x))\n",
    "    return output\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, number_of_features, learning_rate=0.001, number_of_iterations=100):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.number_of_iterations = number_of_iterations\n",
    "        self.beta = np.array(np.random.randn(number_of_features, 1).T[0])\n",
    "        \n",
    "    def train(self, X, y):\n",
    "        #loop principal\n",
    "        for i in range(self.number_of_iterations):\n",
    "            bi = self.prod(X)\n",
    "            h = sigmoid(bi)\n",
    "            errors = y-h\n",
    "            self.beta[1:] += -self.learning_rate*X.T.dot(errors)\n",
    "            self.beta[0] += -self.learning_rate*errors.sum()\n",
    "        return self.beta\n",
    "    \n",
    "    def predict(self, value):\n",
    "        return np.where(sigmoid(self.prod(X))>= 0.5, 0, 1)\n",
    "    \n",
    "    def prod(self, X):\n",
    "        return np.dot(X, self.beta[1:]) + self.beta[0]\n",
    "\n",
    "# Ejemplo de uso de la clase para 3 features\n",
    "log_reg = LogisticRegression(3)\n",
    "print(log_reg.beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2 (1 pto): entrenando el modelo\n",
    "\n",
    "En esta parte tendrás que hacer un clasificador de flores _Iris Virginica_ en base al largo y ancho del pétalo. Así, tu modelo se tiene que comportar como el que vimos en clases, en el que entrenabamos con los largos y anchos de los pétalos del _dataset_ y nuestras respuestas correspondían a si la flor era o no _Iris Virginica_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([21.39679467, 57.55134679, 16.19914656])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris['data'][:, (2,3)] # Nos quedamos solamente con el ancho del pétalo\n",
    "y = (iris['target'] == 2).astype(np.int) # Dejamos True en las filas que son Virginica\n",
    "\n",
    "# Recuerda que vas a tener que usar la versión con bias del dataset\n",
    "# Es decir, añadir una primera columna solamente con 1s\n",
    "X_b = np.c_[np.ones((X.shape[0], 1)), X]\n",
    "\n",
    "# Ahora un ejemplo de como multiplicar la fila 0 con los coeficientes transpuestos (descomentar linea siguiente)\n",
    "log_reg.beta.T.dot(X_b[0,:].reshape(3,1))\n",
    "\n",
    "\n",
    "# Entrena el modelo acá, debería ser como la siguiente línea\n",
    "\n",
    "log_reg.train(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3 (2 pts): entendiendo los resultados de tu modelo\n",
    "\n",
    "En clases vimos un gráfico que en los ejes tenía el largo y el ancho del pétalo, donde podíamos ver de forma gráfica como nuestro modelo genera una recta que divide los puntos que corresponden a las flores _Iris Virginica_ de las que no lo son. En esta parte de la tarea debes hacer el mismo gráfico, pero con los resultados que entregó tu modelo. compara este gráfico con el entregado por SciKit Learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# Evalúa tu modelo acá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parte 4 \\[Bonus\\] (0.5 pts): gradient descent y resultados\n",
    "\n",
    "En esta parte la idea es entender cómo cambia la división de nuestro _dataset_ a medida que pasan las iteraciones del algoritmo de _Gradient Descent_. Por lo mismo la idea es repetir el gráfico de arriba pero esta vez con un _widget_ que nos permita escoger la i-ésima iteración del algoritmo de _Gradient Descent_. El _widget_ debe ir desde 0 a 1000 iteraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realiza el bonus acá"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detalles académicos\n",
    "\n",
    "Este control pueden realizarlo en grupos de hasta dos personas. La entrega de este control debe ser un archivo comprimido donde se encuentre un **Jupyter Notebook**, junto a cualquier archivo que estés llamando desde tu código. **La fecha de entrega es hasta el viernes 9 de octubre, hasta las 20:00 pm, cualquier entrega después de este plazo será calificada con la nota mínima**. La nota se calcula como el número de puntos + un punto base. El archivo comprimido se entrega en un cuestionario de Webcursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
